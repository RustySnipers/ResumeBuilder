nohup: ignoring input
Requirement already satisfied: fastapi==0.115.5 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 4)) (0.115.5)
Requirement already satisfied: uvicorn==0.34.0 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]==0.34.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 5)) (0.34.0)
Requirement already satisfied: pydantic==2.10.3 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 6)) (2.10.3)
Requirement already satisfied: pydantic-settings==2.6.1 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 7)) (2.6.1)
Requirement already satisfied: httpx==0.28.1 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 8)) (0.28.1)
Requirement already satisfied: python-multipart==0.0.18 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 9)) (0.0.18)
Requirement already satisfied: anthropic>=0.40.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 10)) (0.75.0)
Requirement already satisfied: sqlalchemy==2.0.23 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 11)) (2.0.23)
Requirement already satisfied: aiosqlite==0.19.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 12)) (0.19.0)
Requirement already satisfied: email-validator==2.1.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 13)) (2.1.0)
Requirement already satisfied: passlib==1.7.4 in ./.venv/lib/python3.12/site-packages (from passlib[bcrypt]==1.7.4->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 16)) (1.7.4)
Requirement already satisfied: bcrypt==3.2.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 17)) (3.2.0)
Requirement already satisfied: redis==5.0.1 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 18)) (5.0.1)
Requirement already satisfied: python-jose==3.3.0 in ./.venv/lib/python3.12/site-packages (from python-jose[cryptography]==3.3.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 19)) (3.3.0)
Requirement already satisfied: llama-cpp-python>=0.2.23 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 21)) (0.3.16)
Requirement already satisfied: huggingface_hub>=0.19.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 22)) (1.2.1)
Requirement already satisfied: playwright>=1.40.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 23)) (1.56.0)
Requirement already satisfied: beautifulsoup4>=4.12.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 24)) (4.14.3)
Requirement already satisfied: pypdf>=3.17.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 25)) (6.4.0)
Requirement already satisfied: python-docx>=1.1.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 26)) (1.2.0)
Requirement already satisfied: rank_bm25>=0.2.2 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 27)) (0.2.2)
Requirement already satisfied: scikit-learn>=1.3.0 in ./.venv/lib/python3.12/site-packages (from -r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 28)) (1.7.2)
Requirement already satisfied: starlette<0.42.0,>=0.40.0 in ./.venv/lib/python3.12/site-packages (from fastapi==0.115.5->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 4)) (0.41.3)
Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from fastapi==0.115.5->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 4)) (4.15.0)
Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.12/site-packages (from uvicorn==0.34.0->uvicorn[standard]==0.34.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 5)) (8.3.1)
Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.12/site-packages (from uvicorn==0.34.0->uvicorn[standard]==0.34.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 5)) (0.16.0)
Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic==2.10.3->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 6)) (0.7.0)
Requirement already satisfied: pydantic-core==2.27.1 in ./.venv/lib/python3.12/site-packages (from pydantic==2.10.3->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 6)) (2.27.1)
Requirement already satisfied: python-dotenv>=0.21.0 in ./.venv/lib/python3.12/site-packages (from pydantic-settings==2.6.1->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 7)) (1.2.1)
Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx==0.28.1->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 8)) (4.12.0)
Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx==0.28.1->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 8)) (2025.11.12)
Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx==0.28.1->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 8)) (1.0.9)
Requirement already satisfied: idna in ./.venv/lib/python3.12/site-packages (from httpx==0.28.1->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 8)) (3.11)
Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.12/site-packages (from sqlalchemy==2.0.23->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 11)) (3.3.0)
Requirement already satisfied: dnspython>=2.0.0 in ./.venv/lib/python3.12/site-packages (from email-validator==2.1.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 13)) (2.8.0)
Requirement already satisfied: cffi>=1.1 in ./.venv/lib/python3.12/site-packages (from bcrypt==3.2.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 17)) (2.0.0)
Requirement already satisfied: six>=1.4.1 in ./.venv/lib/python3.12/site-packages (from bcrypt==3.2.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 17)) (1.17.0)
Requirement already satisfied: ecdsa!=0.15 in ./.venv/lib/python3.12/site-packages (from python-jose==3.3.0->python-jose[cryptography]==3.3.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 19)) (0.19.1)
Requirement already satisfied: rsa in ./.venv/lib/python3.12/site-packages (from python-jose==3.3.0->python-jose[cryptography]==3.3.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 19)) (4.9.1)
Requirement already satisfied: pyasn1 in ./.venv/lib/python3.12/site-packages (from python-jose==3.3.0->python-jose[cryptography]==3.3.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 19)) (0.6.1)
Requirement already satisfied: cryptography>=3.4.0 in ./.venv/lib/python3.12/site-packages (from python-jose[cryptography]==3.3.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 19)) (46.0.3)
Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]==0.34.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 5)) (0.7.1)
Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]==0.34.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 5)) (6.0.3)
Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]==0.34.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 5)) (0.22.1)
Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]==0.34.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 5)) (1.1.1)
Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]==0.34.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 5)) (15.0.1)
Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from anthropic>=0.40.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 10)) (1.9.0)
Requirement already satisfied: docstring-parser<1,>=0.15 in ./.venv/lib/python3.12/site-packages (from anthropic>=0.40.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 10)) (0.17.0)
Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from anthropic>=0.40.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 10)) (0.12.0)
Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from anthropic>=0.40.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 10)) (1.3.1)
Requirement already satisfied: numpy>=1.20.0 in ./.venv/lib/python3.12/site-packages (from llama-cpp-python>=0.2.23->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 21)) (2.3.5)
Requirement already satisfied: diskcache>=5.6.1 in ./.venv/lib/python3.12/site-packages (from llama-cpp-python>=0.2.23->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 21)) (5.6.3)
Requirement already satisfied: jinja2>=2.11.3 in ./.venv/lib/python3.12/site-packages (from llama-cpp-python>=0.2.23->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 21)) (3.1.6)
Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.19.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 22)) (3.20.0)
Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.19.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 22)) (2025.12.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.19.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 22)) (1.2.0)
Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.19.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 22)) (25.0)
Requirement already satisfied: shellingham in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.19.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 22)) (1.5.4)
Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.19.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 22)) (4.67.1)
Requirement already satisfied: typer-slim in ./.venv/lib/python3.12/site-packages (from huggingface_hub>=0.19.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 22)) (0.20.0)
Requirement already satisfied: pyee<14,>=13 in ./.venv/lib/python3.12/site-packages (from playwright>=1.40.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 23)) (13.0.0)
Requirement already satisfied: soupsieve>=1.6.1 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4>=4.12.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 24)) (2.8)
Requirement already satisfied: lxml>=3.1.0 in ./.venv/lib/python3.12/site-packages (from python-docx>=1.1.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 26)) (6.0.2)
Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.3.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 28)) (1.16.3)
Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.3.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 28)) (1.5.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn>=1.3.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 28)) (3.6.0)
Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=1.1->bcrypt==3.2.0->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 17)) (2.23)
Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2>=2.11.3->llama-cpp-python>=0.2.23->-r /home/owner/Projects/ResumeBuilder/requirements-lite.txt (line 21)) (3.0.3)
INFO:__main__:Initializing database schema...
INFO:__main__:Database schema initialized successfully.
INFO:     Will watch for changes in these directories: ['/home/owner/Projects/ResumeBuilder']
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [1326076] using WatchFiles
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1326078]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
INFO:     127.0.0.1:35640 - "GET /health/live HTTP/1.1" 200 OK
INFO:     127.0.0.1:35654 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:35654 - "GET /assets/index-C6E1muab.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:35662 - "GET /assets/index-DYTB_Oxo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:35662 - "GET /vite.svg HTTP/1.1" 404 Not Found
WARNING:  WatchFiles detected changes in 'repro_txt_upload.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1326078]
WARNING:  WatchFiles detected changes in 'repro_txt_upload.py'. Reloading...
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1326325]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1326344]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
INFO:backend.auth.router:User logged in: testuser@example.com
INFO:     127.0.0.1:49726 - "POST /api/v1/auth/login HTTP/1.1" 200 OK
WARNING:python_multipart.multipart:Skipping data after last boundary
INFO:backend.resumes.parser_service:Parsing file: test.txt (text/plain)
WARNING:backend.resumes.parser_service:Unsupported file type: text/plain
ERROR:backend.resumes.router:Upload failed: 400: Could not extract text from file
INFO:     127.0.0.1:49736 - "POST /api/v1/resumes/upload HTTP/1.1" 500 Internal Server Error
WARNING:  WatchFiles detected changes in 'backend/resumes/parser_service.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1326344]
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1326407]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
INFO:backend.auth.router:User logged in: testuser@example.com
INFO:     127.0.0.1:41584 - "POST /api/v1/auth/login HTTP/1.1" 200 OK
WARNING:python_multipart.multipart:Skipping data after last boundary
INFO:backend.resumes.parser_service:Parsing file: test.txt (text/plain)
INFO:     127.0.0.1:41600 - "POST /api/v1/resumes/upload HTTP/1.1" 201 Created
WARNING:  WatchFiles detected changes in 'repro_txt_upload.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1326407]
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1326510]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
INFO:     127.0.0.1:39828 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:39828 - "GET /assets/index-DYTB_Oxo.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:39834 - "GET /assets/index-C6E1muab.js HTTP/1.1" 304 Not Modified
WARNING:python_multipart.multipart:Skipping data after last boundary
INFO:     127.0.0.1:39834 - "POST /api/v1/resumes/upload HTTP/1.1" 401 Unauthorized
INFO:     127.0.0.1:46328 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:48040 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:48040 - "GET /assets/index-BsZcKI47.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:48054 - "GET /assets/index-DYTB_Oxo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:43906 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:43906 - "GET /assets/index-BsZcKI47.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:43912 - "GET /assets/index-DYTB_Oxo.css HTTP/1.1" 200 OK
INFO:     127.0.0.1:43912 - "GET /vite.svg HTTP/1.1" 404 Not Found
WARNING:  WatchFiles detected changes in 'backend/auth/guest.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1326510]
WARNING:  WatchFiles detected changes in 'backend/auth/guest.py'. Reloading...
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1327535]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1327554]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
WARNING:  WatchFiles detected changes in 'backend/resumes/router.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1327554]
spacy not found. PII detection falling back to regex-only.
Process SpawnProcess-8:
Traceback (most recent call last):
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 66, in run
    return asyncio.run(self.serve(sockets=sockets))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 70, in serve
    await self._serve(sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 77, in _serve
    config.load()
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/config.py", line 435, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/owner/Projects/ResumeBuilder/main.py", line 79, in <module>
    from backend.resumes.router import router as resume_router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/__init__.py", line 6, in <module>
    from backend.resumes.router import router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/router.py", line 105, in <module>
    current_user: User = Depends(get_current_active_user),
                                 ^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'get_current_active_user' is not defined
WARNING:  WatchFiles detected changes in 'backend/jobs/router.py'. Reloading...
spacy not found. PII detection falling back to regex-only.
Process SpawnProcess-9:
Traceback (most recent call last):
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 66, in run
    return asyncio.run(self.serve(sockets=sockets))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 70, in serve
    await self._serve(sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 77, in _serve
    config.load()
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/config.py", line 435, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/owner/Projects/ResumeBuilder/main.py", line 79, in <module>
    from backend.resumes.router import router as resume_router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/__init__.py", line 6, in <module>
    from backend.resumes.router import router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/router.py", line 105, in <module>
    current_user: User = Depends(get_current_active_user),
                                 ^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'get_current_active_user' is not defined
WARNING:  WatchFiles detected changes in 'backend/export/router.py'. Reloading...
spacy not found. PII detection falling back to regex-only.
Process SpawnProcess-10:
Traceback (most recent call last):
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 66, in run
    return asyncio.run(self.serve(sockets=sockets))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 70, in serve
    await self._serve(sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 77, in _serve
    config.load()
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/config.py", line 435, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/owner/Projects/ResumeBuilder/main.py", line 79, in <module>
    from backend.resumes.router import router as resume_router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/__init__.py", line 6, in <module>
    from backend.resumes.router import router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/router.py", line 105, in <module>
    current_user: User = Depends(get_current_active_user),
                                 ^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'get_current_active_user' is not defined
WARNING:  WatchFiles detected changes in 'test_guest_upload.py'. Reloading...
WARNING:  WatchFiles detected changes in 'test_guest_upload.py'. Reloading...
spacy not found. PII detection falling back to regex-only.
Process SpawnProcess-11:
Traceback (most recent call last):
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 66, in run
    return asyncio.run(self.serve(sockets=sockets))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 70, in serve
    await self._serve(sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 77, in _serve
    config.load()
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/config.py", line 435, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/owner/Projects/ResumeBuilder/main.py", line 79, in <module>
    from backend.resumes.router import router as resume_router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/__init__.py", line 6, in <module>
    from backend.resumes.router import router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/router.py", line 105, in <module>
    current_user: User = Depends(get_current_active_user),
                                 ^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'get_current_active_user' is not defined
spacy not found. PII detection falling back to regex-only.
Process SpawnProcess-12:
Traceback (most recent call last):
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 66, in run
    return asyncio.run(self.serve(sockets=sockets))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 70, in serve
    await self._serve(sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 77, in _serve
    config.load()
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/config.py", line 435, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/owner/Projects/ResumeBuilder/main.py", line 79, in <module>
    from backend.resumes.router import router as resume_router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/__init__.py", line 6, in <module>
    from backend.resumes.router import router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/router.py", line 105, in <module>
    current_user: User = Depends(get_current_active_user),
                                 ^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'get_current_active_user' is not defined
WARNING:  WatchFiles detected changes in 'backend/resumes/router.py'. Reloading...
spacy not found. PII detection falling back to regex-only.
Process SpawnProcess-13:
Traceback (most recent call last):
  File "/usr/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/_subprocess.py", line 80, in subprocess_started
    target(sockets=sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 66, in run
    return asyncio.run(self.serve(sockets=sockets))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 70, in serve
    await self._serve(sockets)
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/server.py", line 77, in _serve
    config.load()
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/config.py", line 435, in load
    self.loaded_app = import_from_string(self.app)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/uvicorn/importer.py", line 19, in import_from_string
    module = importlib.import_module(module_str)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/home/owner/Projects/ResumeBuilder/main.py", line 79, in <module>
    from backend.resumes.router import router as resume_router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/__init__.py", line 6, in <module>
    from backend.resumes.router import router
  File "/home/owner/Projects/ResumeBuilder/backend/resumes/router.py", line 187, in <module>
    current_user: User = Depends(get_current_active_user),
                                 ^^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'get_current_active_user' is not defined
WARNING:  WatchFiles detected changes in 'backend/resumes/router.py'. Reloading...
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1328167]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
WARNING:python_multipart.multipart:Skipping data after last boundary
INFO:backend.auth.guest:Creating Guest User
ERROR:backend.auth.guest:Failed to get/create Guest User: 'is_superuser' is an invalid keyword argument for User
INFO:backend.resumes.parser_service:Parsing file: resume_jesse_brand.pdf (application/pdf)
INFO:     127.0.0.1:49056 - "POST /api/v1/resumes/upload HTTP/1.1" 201 Created
WARNING:python_multipart.multipart:Skipping data after last boundary
INFO:backend.auth.guest:Creating Guest User
ERROR:backend.auth.guest:Failed to get/create Guest User: 'is_superuser' is an invalid keyword argument for User
INFO:backend.resumes.parser_service:Parsing file: resume_jesse_brand.pdf (application/pdf)
INFO:     127.0.0.1:58988 - "POST /api/v1/resumes/upload HTTP/1.1" 201 Created
WARNING:  WatchFiles detected changes in 'backend/auth/guest.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1328167]
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1328296]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
WARNING:python_multipart.multipart:Skipping data after last boundary
INFO:backend.auth.guest:Creating Guest User
INFO:backend.resumes.parser_service:Parsing file: resume_jesse_brand.pdf (application/pdf)
INFO:     127.0.0.1:56060 - "POST /api/v1/resumes/upload HTTP/1.1" 201 Created
WARNING:  WatchFiles detected changes in 'test_guest_upload.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1328296]
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1328368]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
INFO:     127.0.0.1:35204 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:35204 - "GET /assets/index-D-Tk-A7r.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:35214 - "GET /assets/index-DYTB_Oxo.css HTTP/1.1" 200 OK
WARNING:python_multipart.multipart:Skipping data after last boundary
INFO:backend.resumes.parser_service:Parsing file: resume_jesse_brand.pdf (application/pdf)
INFO:     127.0.0.1:37080 - "POST /api/v1/resumes/upload HTTP/1.1" 201 Created
INFO:backend.llm.local_llm_client:Checking for local model: TheBloke/Llama-2-7B-Chat-GGUF/llama-2-7b-chat.Q4_K_M.gguf...
/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `hf_hub_download`. Downloading to a local directory does not use symlinks anymore.
  warnings.warn(
INFO:httpx:HTTP Request: HEAD https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf "HTTP/1.1 302 Found"
INFO:backend.llm.local_llm_client:Model found/downloaded at: /home/owner/.cache/resume-builder/models/llama-2-7b-chat.Q4_K_M.gguf
INFO:backend.llm.local_llm_client:Loading Local LLM from /home/owner/.cache/resume-builder/models/llama-2-7b-chat.Q4_K_M.gguf...
llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /home/owner/.cache/resume-builder/models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.name str              = LLaMA v2
llama_model_loader: - kv   2:                       llama.context_length u32              = 4096
llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096
llama_model_loader: - kv   4:                          llama.block_count u32              = 32
llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008
llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32
llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32
llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  10:                          general.file_type u32              = 15
llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama
llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = ["<unk>", "<s>", "</s>", "<0x00>", "<...
llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...
llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...
llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  18:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   65 tensors
llama_model_loader: - type q4_K:  193 tensors
llama_model_loader: - type q6_K:   33 tensors
print_info: file format = GGUF V2
print_info: file type   = Q4_K - Medium
print_info: file size   = 3.80 GiB (4.84 BPW) 
init_tokenizer: initializing tokenizer for type 1
load: control token:      2 '</s>' is not marked as EOG
load: control token:      1 '<s>' is not marked as EOG
load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: printing all EOG tokens:
load:   - 2 ('</s>')
load: special tokens cache size = 3
load: token to piece cache size = 0.1684 MB
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: n_ctx_train      = 4096
print_info: n_embd           = 4096
print_info: n_layer          = 32
print_info: n_head           = 32
print_info: n_head_kv        = 32
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: is_swa_any       = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 1
print_info: n_embd_k_gqa     = 4096
print_info: n_embd_v_gqa     = 4096
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-06
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 11008
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 10000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 4096
print_info: rope_finetuned   = unknown
print_info: model type       = 7B
print_info: model params     = 6.74 B
print_info: general.name     = LLaMA v2
print_info: vocab type       = SPM
print_info: n_vocab          = 32000
print_info: n_merges         = 0
print_info: BOS token        = 1 '<s>'
print_info: EOS token        = 2 '</s>'
print_info: UNK token        = 0 '<unk>'
print_info: LF token         = 13 '<0x0A>'
print_info: EOG token        = 2 '</s>'
print_info: max token length = 48
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU, is_swa = 0
load_tensors: layer   1 assigned to device CPU, is_swa = 0
load_tensors: layer   2 assigned to device CPU, is_swa = 0
load_tensors: layer   3 assigned to device CPU, is_swa = 0
load_tensors: layer   4 assigned to device CPU, is_swa = 0
load_tensors: layer   5 assigned to device CPU, is_swa = 0
load_tensors: layer   6 assigned to device CPU, is_swa = 0
load_tensors: layer   7 assigned to device CPU, is_swa = 0
load_tensors: layer   8 assigned to device CPU, is_swa = 0
load_tensors: layer   9 assigned to device CPU, is_swa = 0
load_tensors: layer  10 assigned to device CPU, is_swa = 0
load_tensors: layer  11 assigned to device CPU, is_swa = 0
load_tensors: layer  12 assigned to device CPU, is_swa = 0
load_tensors: layer  13 assigned to device CPU, is_swa = 0
load_tensors: layer  14 assigned to device CPU, is_swa = 0
load_tensors: layer  15 assigned to device CPU, is_swa = 0
load_tensors: layer  16 assigned to device CPU, is_swa = 0
load_tensors: layer  17 assigned to device CPU, is_swa = 0
load_tensors: layer  18 assigned to device CPU, is_swa = 0
load_tensors: layer  19 assigned to device CPU, is_swa = 0
load_tensors: layer  20 assigned to device CPU, is_swa = 0
load_tensors: layer  21 assigned to device CPU, is_swa = 0
load_tensors: layer  22 assigned to device CPU, is_swa = 0
load_tensors: layer  23 assigned to device CPU, is_swa = 0
load_tensors: layer  24 assigned to device CPU, is_swa = 0
load_tensors: layer  25 assigned to device CPU, is_swa = 0
load_tensors: layer  26 assigned to device CPU, is_swa = 0
load_tensors: layer  27 assigned to device CPU, is_swa = 0
load_tensors: layer  28 assigned to device CPU, is_swa = 0
load_tensors: layer  29 assigned to device CPU, is_swa = 0
load_tensors: layer  30 assigned to device CPU, is_swa = 0
load_tensors: layer  31 assigned to device CPU, is_swa = 0
load_tensors: layer  32 assigned to device CPU, is_swa = 0
load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  3891.24 MiB
..................................................................................................
llama_context: constructing llama_context
llama_context: n_seq_max     = 1
llama_context: n_ctx         = 2048
llama_context: n_ctx_per_seq = 2048
llama_context: n_batch       = 512
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: kv_unified    = false
llama_context: freq_base     = 10000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized
set_abort_callback: call
llama_context:        CPU  output buffer size =     0.12 MiB
create_memory: n_ctx = 2048 (padded)
llama_kv_cache_unified: layer   0: dev = CPU
llama_kv_cache_unified: layer   1: dev = CPU
llama_kv_cache_unified: layer   2: dev = CPU
llama_kv_cache_unified: layer   3: dev = CPU
llama_kv_cache_unified: layer   4: dev = CPU
llama_kv_cache_unified: layer   5: dev = CPU
llama_kv_cache_unified: layer   6: dev = CPU
llama_kv_cache_unified: layer   7: dev = CPU
llama_kv_cache_unified: layer   8: dev = CPU
llama_kv_cache_unified: layer   9: dev = CPU
llama_kv_cache_unified: layer  10: dev = CPU
llama_kv_cache_unified: layer  11: dev = CPU
llama_kv_cache_unified: layer  12: dev = CPU
llama_kv_cache_unified: layer  13: dev = CPU
llama_kv_cache_unified: layer  14: dev = CPU
llama_kv_cache_unified: layer  15: dev = CPU
llama_kv_cache_unified: layer  16: dev = CPU
llama_kv_cache_unified: layer  17: dev = CPU
llama_kv_cache_unified: layer  18: dev = CPU
llama_kv_cache_unified: layer  19: dev = CPU
llama_kv_cache_unified: layer  20: dev = CPU
llama_kv_cache_unified: layer  21: dev = CPU
llama_kv_cache_unified: layer  22: dev = CPU
llama_kv_cache_unified: layer  23: dev = CPU
llama_kv_cache_unified: layer  24: dev = CPU
llama_kv_cache_unified: layer  25: dev = CPU
llama_kv_cache_unified: layer  26: dev = CPU
llama_kv_cache_unified: layer  27: dev = CPU
llama_kv_cache_unified: layer  28: dev = CPU
llama_kv_cache_unified: layer  29: dev = CPU
llama_kv_cache_unified: layer  30: dev = CPU
llama_kv_cache_unified: layer  31: dev = CPU
llama_kv_cache_unified:        CPU KV buffer size =  1024.00 MiB
llama_kv_cache_unified: size = 1024.00 MiB (  2048 cells,  32 layers,  1/1 seqs), K (f16):  512.00 MiB, V (f16):  512.00 MiB
llama_context: enumerating backends
llama_context: backend_ptrs.size() = 1
llama_context: max_nodes = 2328
llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0
graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512
graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1
graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512
llama_context:        CPU compute buffer size =   180.01 MiB
llama_context: graph nodes  = 1126
llama_context: graph splits = 1
CPU : SSE3 = 1 | SSSE3 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | 
Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}
Using fallback chat format: llama-2
INFO:backend.llm.local_llm_client:Local LLM loaded successfully.
INFO:backend.scraping.service:Scraping URL: https://job-boards.greenhouse.io/weedmaps77/jobs/8310414002?gh_src=0cb2d2f52
llama_perf_context_print:        load time =  312676.50 ms
llama_perf_context_print: prompt eval time =  312674.95 ms /   803 tokens (  389.38 ms per token,     2.57 tokens per second)
llama_perf_context_print:        eval time =  286320.21 ms /   499 runs   (  573.79 ms per token,     1.74 tokens per second)
llama_perf_context_print:       total time =  599602.16 ms /  1302 tokens
llama_perf_context_print:    graphs reused =        483
INFO:     127.0.0.1:56830 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:34624 - "POST /api/v1/jobs/analyze HTTP/1.1" 200 OK
INFO:     127.0.0.1:56830 - "GET /assets/index-DrD9WvVp.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:53694 - "GET /assets/index-DYTB_Oxo.css HTTP/1.1" 200 OK
WARNING:python_multipart.multipart:Skipping data after last boundary
INFO:backend.resumes.parser_service:Parsing file: resume_jesse_brand.pdf (application/pdf)
INFO:     127.0.0.1:42646 - "POST /api/v1/resumes/upload HTTP/1.1" 201 Created
INFO:backend.llm.local_llm_client:Checking for local model: TheBloke/Llama-2-7B-Chat-GGUF/llama-2-7b-chat.Q4_K_M.gguf...
/home/owner/Projects/ResumeBuilder/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `hf_hub_download`. Downloading to a local directory does not use symlinks anymore.
  warnings.warn(
INFO:httpx:HTTP Request: HEAD https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf "HTTP/1.1 302 Found"
INFO:backend.llm.local_llm_client:Model found/downloaded at: /home/owner/.cache/resume-builder/models/llama-2-7b-chat.Q4_K_M.gguf
INFO:backend.llm.local_llm_client:Loading Local LLM from /home/owner/.cache/resume-builder/models/llama-2-7b-chat.Q4_K_M.gguf...
llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /home/owner/.cache/resume-builder/models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)
llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.
llama_model_loader: - kv   0:                       general.architecture str              = llama
llama_model_loader: - kv   1:                               general.name str              = LLaMA v2
llama_model_loader: - kv   2:                       llama.context_length u32              = 4096
llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096
llama_model_loader: - kv   4:                          llama.block_count u32              = 32
llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008
llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128
llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32
llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32
llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001
llama_model_loader: - kv  10:                          general.file_type u32              = 15
llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama
llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = ["<unk>", "<s>", "</s>", "<0x00>", "<...
llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...
llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...
llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1
llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2
llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0
llama_model_loader: - kv  18:               general.quantization_version u32              = 2
llama_model_loader: - type  f32:   65 tensors
llama_model_loader: - type q4_K:  193 tensors
llama_model_loader: - type q6_K:   33 tensors
print_info: file format = GGUF V2
print_info: file type   = Q4_K - Medium
print_info: file size   = 3.80 GiB (4.84 BPW) 
init_tokenizer: initializing tokenizer for type 1
load: control token:      2 '</s>' is not marked as EOG
load: control token:      1 '<s>' is not marked as EOG
load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect
load: printing all EOG tokens:
load:   - 2 ('</s>')
load: special tokens cache size = 3
load: token to piece cache size = 0.1684 MB
print_info: arch             = llama
print_info: vocab_only       = 0
print_info: n_ctx_train      = 4096
print_info: n_embd           = 4096
print_info: n_layer          = 32
print_info: n_head           = 32
print_info: n_head_kv        = 32
print_info: n_rot            = 128
print_info: n_swa            = 0
print_info: is_swa_any       = 0
print_info: n_embd_head_k    = 128
print_info: n_embd_head_v    = 128
print_info: n_gqa            = 1
print_info: n_embd_k_gqa     = 4096
print_info: n_embd_v_gqa     = 4096
print_info: f_norm_eps       = 0.0e+00
print_info: f_norm_rms_eps   = 1.0e-06
print_info: f_clamp_kqv      = 0.0e+00
print_info: f_max_alibi_bias = 0.0e+00
print_info: f_logit_scale    = 0.0e+00
print_info: f_attn_scale     = 0.0e+00
print_info: n_ff             = 11008
print_info: n_expert         = 0
print_info: n_expert_used    = 0
print_info: causal attn      = 1
print_info: pooling type     = 0
print_info: rope type        = 0
print_info: rope scaling     = linear
print_info: freq_base_train  = 10000.0
print_info: freq_scale_train = 1
print_info: n_ctx_orig_yarn  = 4096
print_info: rope_finetuned   = unknown
print_info: model type       = 7B
print_info: model params     = 6.74 B
print_info: general.name     = LLaMA v2
print_info: vocab type       = SPM
print_info: n_vocab          = 32000
print_info: n_merges         = 0
print_info: BOS token        = 1 '<s>'
print_info: EOS token        = 2 '</s>'
print_info: UNK token        = 0 '<unk>'
print_info: LF token         = 13 '<0x0A>'
print_info: EOG token        = 2 '</s>'
print_info: max token length = 48
load_tensors: loading model tensors, this can take a while... (mmap = true)
load_tensors: layer   0 assigned to device CPU, is_swa = 0
load_tensors: layer   1 assigned to device CPU, is_swa = 0
load_tensors: layer   2 assigned to device CPU, is_swa = 0
load_tensors: layer   3 assigned to device CPU, is_swa = 0
load_tensors: layer   4 assigned to device CPU, is_swa = 0
load_tensors: layer   5 assigned to device CPU, is_swa = 0
load_tensors: layer   6 assigned to device CPU, is_swa = 0
load_tensors: layer   7 assigned to device CPU, is_swa = 0
load_tensors: layer   8 assigned to device CPU, is_swa = 0
load_tensors: layer   9 assigned to device CPU, is_swa = 0
load_tensors: layer  10 assigned to device CPU, is_swa = 0
load_tensors: layer  11 assigned to device CPU, is_swa = 0
load_tensors: layer  12 assigned to device CPU, is_swa = 0
load_tensors: layer  13 assigned to device CPU, is_swa = 0
load_tensors: layer  14 assigned to device CPU, is_swa = 0
load_tensors: layer  15 assigned to device CPU, is_swa = 0
load_tensors: layer  16 assigned to device CPU, is_swa = 0
load_tensors: layer  17 assigned to device CPU, is_swa = 0
load_tensors: layer  18 assigned to device CPU, is_swa = 0
load_tensors: layer  19 assigned to device CPU, is_swa = 0
load_tensors: layer  20 assigned to device CPU, is_swa = 0
load_tensors: layer  21 assigned to device CPU, is_swa = 0
load_tensors: layer  22 assigned to device CPU, is_swa = 0
load_tensors: layer  23 assigned to device CPU, is_swa = 0
load_tensors: layer  24 assigned to device CPU, is_swa = 0
load_tensors: layer  25 assigned to device CPU, is_swa = 0
load_tensors: layer  26 assigned to device CPU, is_swa = 0
load_tensors: layer  27 assigned to device CPU, is_swa = 0
load_tensors: layer  28 assigned to device CPU, is_swa = 0
load_tensors: layer  29 assigned to device CPU, is_swa = 0
load_tensors: layer  30 assigned to device CPU, is_swa = 0
load_tensors: layer  31 assigned to device CPU, is_swa = 0
load_tensors: layer  32 assigned to device CPU, is_swa = 0
load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead
load_tensors:   CPU_Mapped model buffer size =  3891.24 MiB
..................................................................................................
llama_context: constructing llama_context
llama_context: n_seq_max     = 1
llama_context: n_ctx         = 2048
llama_context: n_ctx_per_seq = 2048
llama_context: n_batch       = 512
llama_context: n_ubatch      = 512
llama_context: causal_attn   = 1
llama_context: flash_attn    = 0
llama_context: kv_unified    = false
llama_context: freq_base     = 10000.0
llama_context: freq_scale    = 1
llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized
set_abort_callback: call
llama_context:        CPU  output buffer size =     0.12 MiB
create_memory: n_ctx = 2048 (padded)
llama_kv_cache_unified: layer   0: dev = CPU
llama_kv_cache_unified: layer   1: dev = CPU
llama_kv_cache_unified: layer   2: dev = CPU
llama_kv_cache_unified: layer   3: dev = CPU
llama_kv_cache_unified: layer   4: dev = CPU
llama_kv_cache_unified: layer   5: dev = CPU
llama_kv_cache_unified: layer   6: dev = CPU
llama_kv_cache_unified: layer   7: dev = CPU
llama_kv_cache_unified: layer   8: dev = CPU
llama_kv_cache_unified: layer   9: dev = CPU
llama_kv_cache_unified: layer  10: dev = CPU
llama_kv_cache_unified: layer  11: dev = CPU
llama_kv_cache_unified: layer  12: dev = CPU
llama_kv_cache_unified: layer  13: dev = CPU
llama_kv_cache_unified: layer  14: dev = CPU
llama_kv_cache_unified: layer  15: dev = CPU
llama_kv_cache_unified: layer  16: dev = CPU
llama_kv_cache_unified: layer  17: dev = CPU
llama_kv_cache_unified: layer  18: dev = CPU
llama_kv_cache_unified: layer  19: dev = CPU
llama_kv_cache_unified: layer  20: dev = CPU
llama_kv_cache_unified: layer  21: dev = CPU
llama_kv_cache_unified: layer  22: dev = CPU
llama_kv_cache_unified: layer  23: dev = CPU
llama_kv_cache_unified: layer  24: dev = CPU
llama_kv_cache_unified: layer  25: dev = CPU
llama_kv_cache_unified: layer  26: dev = CPU
llama_kv_cache_unified: layer  27: dev = CPU
llama_kv_cache_unified: layer  28: dev = CPU
llama_kv_cache_unified: layer  29: dev = CPU
llama_kv_cache_unified: layer  30: dev = CPU
llama_kv_cache_unified: layer  31: dev = CPU
llama_kv_cache_unified:        CPU KV buffer size =  1024.00 MiB
llama_kv_cache_unified: size = 1024.00 MiB (  2048 cells,  32 layers,  1/1 seqs), K (f16):  512.00 MiB, V (f16):  512.00 MiB
llama_context: enumerating backends
llama_context: backend_ptrs.size() = 1
llama_context: max_nodes = 2328
llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0
graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512
graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1
graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512
llama_context:        CPU compute buffer size =   180.01 MiB
llama_context: graph nodes  = 1126
llama_context: graph splits = 1
CPU : SSE3 = 1 | SSSE3 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | 
Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}
Using fallback chat format: llama-2
INFO:backend.llm.local_llm_client:Local LLM loaded successfully.
INFO:backend.scraping.service:Scraping URL: https://job-boards.greenhouse.io/weedmaps77/jobs/8310414002?gh_src=0cb2d2f52
WARNING:  WatchFiles detected changes in 'backend/export/docx_generator.py'. Reloading...
llama_perf_context_print:        load time =  359697.65 ms
llama_perf_context_print: prompt eval time =  359695.74 ms /   803 tokens (  447.94 ms per token,     2.23 tokens per second)
llama_perf_context_print:        eval time =  368124.80 ms /   499 runs   (  737.73 ms per token,     1.36 tokens per second)
llama_perf_context_print:       total time =  728553.61 ms /  1302 tokens
llama_perf_context_print:    graphs reused =        483
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1328368]
WARNING:  WatchFiles detected changes in 'verify_strict_ats.py'. Reloading...
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1347075]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
spacy not found. PII detection falling back to regex-only.
INFO:     Started server process [1347103]
INFO:     Waiting for application startup.
INFO:main:Startup: Lite mode detected - skipping Redis-backed services
WARNING:main:Startup: ANTHROPIC_API_KEY not set - LLM endpoints will return 503 until configured
INFO:     Application startup complete.
INFO:     127.0.0.1:43368 - "GET / HTTP/1.1" 200 OK
INFO:     127.0.0.1:43368 - "GET /assets/index-B1i46r9-.js HTTP/1.1" 200 OK
INFO:     127.0.0.1:43376 - "GET /assets/index-DYTB_Oxo.css HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1347103]
INFO:     Stopping reloader process [1326076]
